{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11583d57",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:46.238917Z",
     "iopub.status.busy": "2025-11-30T18:19:46.238266Z",
     "iopub.status.idle": "2025-11-30T18:19:48.424810Z",
     "shell.execute_reply": "2025-11-30T18:19:48.423117Z"
    },
    "papermill": {
     "duration": 2.196201,
     "end_time": "2025-11-30T18:19:48.426710",
     "exception": false,
     "start_time": "2025-11-30T18:19:46.230509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/movie_theater_id_relation/movie_theater_id_relation.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/date_info/date_info.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/sample_submission/sample_submission.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/booknow_theaters/booknow_theaters.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/cinePOS_booking/cinePOS_booking.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/cinePOS_theaters/cinePOS_theaters.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/booknow_visits/booknow_visits.csv\n",
      "/kaggle/input/Cinema_Audience_Forecasting_challenge/booknow_booking/booknow_booking.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b3beb",
   "metadata": {
    "papermill": {
     "duration": 0.005396,
     "end_time": "2025-11-30T18:19:48.437903",
     "exception": false,
     "start_time": "2025-11-30T18:19:48.432507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84abd918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:48.450845Z",
     "iopub.status.busy": "2025-11-30T18:19:48.449593Z",
     "iopub.status.idle": "2025-11-30T18:19:50.526856Z",
     "shell.execute_reply": "2025-11-30T18:19:50.525841Z"
    },
    "papermill": {
     "duration": 2.085779,
     "end_time": "2025-11-30T18:19:50.528870",
     "exception": false,
     "start_time": "2025-11-30T18:19:48.443091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a80ce",
   "metadata": {
    "papermill": {
     "duration": 0.005251,
     "end_time": "2025-11-30T18:19:50.539717",
     "exception": false,
     "start_time": "2025-11-30T18:19:50.534466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "247b90a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:50.552072Z",
     "iopub.status.busy": "2025-11-30T18:19:50.551438Z",
     "iopub.status.idle": "2025-11-30T18:19:52.722125Z",
     "shell.execute_reply": "2025-11-30T18:19:52.721083Z"
    },
    "papermill": {
     "duration": 2.179369,
     "end_time": "2025-11-30T18:19:52.724298",
     "exception": false,
     "start_time": "2025-11-30T18:19:50.544929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visits shape: (214046, 3)\n",
      "Sample submission shape: (38062, 2)\n"
     ]
    }
   ],
   "source": [
    "visits = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/booknow_visits/booknow_visits.csv')\n",
    "book_booking = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/booknow_booking/booknow_booking.csv')\n",
    "cine_booking = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/cinePOS_booking/cinePOS_booking.csv')\n",
    "book_theaters = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/booknow_theaters/booknow_theaters.csv')\n",
    "cine_theaters = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/cinePOS_theaters/cinePOS_theaters.csv')\n",
    "theater_mapping = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/movie_theater_id_relation/movie_theater_id_relation.csv')\n",
    "date_info = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/date_info/date_info.csv')\n",
    "sample_submission = pd.read_csv('/kaggle/input/Cinema_Audience_Forecasting_challenge/sample_submission/sample_submission.csv')\n",
    "\n",
    "print(f\"Visits shape: {visits.shape}\")\n",
    "print(f\"Sample submission shape: {sample_submission.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263a41e2",
   "metadata": {
    "papermill": {
     "duration": 0.005408,
     "end_time": "2025-11-30T18:19:52.735658",
     "exception": false,
     "start_time": "2025-11-30T18:19:52.730250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Cleanup and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaca857a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:52.747825Z",
     "iopub.status.busy": "2025-11-30T18:19:52.747495Z",
     "iopub.status.idle": "2025-11-30T18:19:53.741258Z",
     "shell.execute_reply": "2025-11-30T18:19:53.740129Z"
    },
    "papermill": {
     "duration": 1.002191,
     "end_time": "2025-11-30T18:19:53.743157",
     "exception": false,
     "start_time": "2025-11-30T18:19:52.740966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "visits['show_date'] = pd.to_datetime(visits['show_date'])\n",
    "book_booking['show_datetime'] = pd.to_datetime(book_booking['show_datetime'])\n",
    "book_booking['booking_datetime'] = pd.to_datetime(book_booking['booking_datetime'])\n",
    "cine_booking['show_datetime'] = pd.to_datetime(cine_booking['show_datetime'])\n",
    "cine_booking['booking_datetime'] = pd.to_datetime(cine_booking['booking_datetime'])\n",
    "date_info['show_date'] = pd.to_datetime(date_info['show_date'])\n",
    "\n",
    "# Extract show_date from booking data\n",
    "book_booking['show_date'] = book_booking['show_datetime'].dt.date\n",
    "cine_booking['show_date'] = cine_booking['show_datetime'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449cfef7",
   "metadata": {
    "papermill": {
     "duration": 0.005449,
     "end_time": "2025-11-30T18:19:53.754055",
     "exception": false,
     "start_time": "2025-11-30T18:19:53.748606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fe4cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:53.767057Z",
     "iopub.status.busy": "2025-11-30T18:19:53.765957Z",
     "iopub.status.idle": "2025-11-30T18:19:54.648537Z",
     "shell.execute_reply": "2025-11-30T18:19:54.647294Z"
    },
    "papermill": {
     "duration": 0.891161,
     "end_time": "2025-11-30T18:19:54.650608",
     "exception": false,
     "start_time": "2025-11-30T18:19:53.759447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BookNow booking aggregations by theater and date\n",
    "book_agg = book_booking.groupby(['book_theater_id', 'show_date']).agg({\n",
    "    'tickets_booked': ['sum', 'mean', 'count', 'max']\n",
    "}).reset_index()\n",
    "book_agg.columns = ['book_theater_id', 'show_date', 'book_tickets_sum', \n",
    "                    'book_tickets_mean', 'book_booking_count', 'book_tickets_max']\n",
    "book_agg['show_date'] = pd.to_datetime(book_agg['show_date'])\n",
    "\n",
    "# CinePOS booking aggregations - map to BookNow IDs first\n",
    "cine_booking_mapped = cine_booking.merge(theater_mapping, on='cine_theater_id', how='left')\n",
    "cine_agg = cine_booking_mapped.groupby(['book_theater_id', 'show_date']).agg({\n",
    "    'tickets_sold': ['sum', 'mean', 'count', 'max']\n",
    "}).reset_index()\n",
    "cine_agg.columns = ['book_theater_id', 'show_date', 'cine_tickets_sum',\n",
    "                    'cine_tickets_mean', 'cine_booking_count', 'cine_tickets_max']\n",
    "cine_agg['show_date'] = pd.to_datetime(cine_agg['show_date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e77285",
   "metadata": {
    "papermill": {
     "duration": 0.005403,
     "end_time": "2025-11-30T18:19:54.661537",
     "exception": false,
     "start_time": "2025-11-30T18:19:54.656134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade2f4a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:54.674456Z",
     "iopub.status.busy": "2025-11-30T18:19:54.673302Z",
     "iopub.status.idle": "2025-11-30T18:19:54.893773Z",
     "shell.execute_reply": "2025-11-30T18:19:54.892468Z"
    },
    "papermill": {
     "duration": 0.228772,
     "end_time": "2025-11-30T18:19:54.895612",
     "exception": false,
     "start_time": "2025-11-30T18:19:54.666840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start with visits (training data)\n",
    "df = visits.copy()\n",
    "\n",
    "# Merge date info\n",
    "df = df.merge(date_info, on='show_date', how='left')\n",
    "\n",
    "# Clean book_theaters data\n",
    "book_theaters_clean = book_theaters.dropna(subset=['book_theater_id'])\n",
    "\n",
    "# Merge theater info (handle nulls in book_theater_id)\n",
    "df = df.merge(book_theaters_clean[['book_theater_id', 'theater_type', 'theater_area']], \n",
    "              on='book_theater_id', how='left')\n",
    "\n",
    "# Merge booking features\n",
    "df = df.merge(book_agg, on=['book_theater_id', 'show_date'], how='left')\n",
    "df = df.merge(cine_agg, on=['book_theater_id', 'show_date'], how='left')\n",
    "\n",
    "# Fill missing booking features with 0\n",
    "booking_cols = ['book_tickets_sum', 'book_tickets_mean', 'book_booking_count', 'book_tickets_max',\n",
    "                'cine_tickets_sum', 'cine_tickets_mean', 'cine_booking_count', 'cine_tickets_max']\n",
    "df[booking_cols] = df[booking_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979ca6e",
   "metadata": {
    "papermill": {
     "duration": 0.005281,
     "end_time": "2025-11-30T18:19:54.906489",
     "exception": false,
     "start_time": "2025-11-30T18:19:54.901208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Time Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3c38f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:54.918393Z",
     "iopub.status.busy": "2025-11-30T18:19:54.918086Z",
     "iopub.status.idle": "2025-11-30T18:19:55.041441Z",
     "shell.execute_reply": "2025-11-30T18:19:55.040182Z"
    },
    "papermill": {
     "duration": 0.131827,
     "end_time": "2025-11-30T18:19:55.043595",
     "exception": false,
     "start_time": "2025-11-30T18:19:54.911768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['year'] = df['show_date'].dt.year\n",
    "df['month'] = df['show_date'].dt.month\n",
    "df['day'] = df['show_date'].dt.day\n",
    "df['day_of_year'] = df['show_date'].dt.dayofyear\n",
    "df['week_of_year'] = df['show_date'].dt.isocalendar().week\n",
    "df['is_weekend'] = df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "df['is_friday'] = (df['day_of_week'] == 'Friday').astype(int)\n",
    "df['quarter'] = df['show_date'].dt.quarter\n",
    "\n",
    "# Advanced time features\n",
    "df['is_month_end'] = (df['show_date'].dt.day > 25).astype(int)\n",
    "df['is_month_start'] = (df['show_date'].dt.day <= 5).astype(int)\n",
    "df['season'] = (df['month'] % 12 + 3) // 3\n",
    "\n",
    "# Days to weekend\n",
    "df['days_to_weekend'] = df['day_of_week'].map({\n",
    "    'Monday': 5, 'Tuesday': 4, 'Wednesday': 3, 'Thursday': 2,\n",
    "    'Friday': 1, 'Saturday': 0, 'Sunday': 0\n",
    "})\n",
    "\n",
    "# Interaction features\n",
    "df['weekend_x_month'] = df['is_weekend'] * df['month']\n",
    "df['weekend_x_quarter'] = df['is_weekend'] * df['quarter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f3085b",
   "metadata": {
    "papermill": {
     "duration": 0.005404,
     "end_time": "2025-11-30T18:19:55.055092",
     "exception": false,
     "start_time": "2025-11-30T18:19:55.049688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Lag Features and Theater Level Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc8dcc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:55.068235Z",
     "iopub.status.busy": "2025-11-30T18:19:55.067499Z",
     "iopub.status.idle": "2025-11-30T18:19:58.763422Z",
     "shell.execute_reply": "2025-11-30T18:19:58.762040Z"
    },
    "papermill": {
     "duration": 3.704521,
     "end_time": "2025-11-30T18:19:58.765380",
     "exception": false,
     "start_time": "2025-11-30T18:19:55.060859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(['book_theater_id', 'show_date'])\n",
    "\n",
    "# Add more lag periods\n",
    "for lag in [1, 3, 7, 14, 21, 28]:\n",
    "    df[f'audience_lag_{lag}'] = df.groupby('book_theater_id')['audience_count'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "for window in [7, 14, 21, 28]:\n",
    "    df[f'audience_roll_mean_{window}'] = df.groupby('book_theater_id')['audience_count'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    df[f'audience_roll_std_{window}'] = df.groupby('book_theater_id')['audience_count'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).std().shift(1)\n",
    "    )\n",
    "    df[f'audience_roll_max_{window}'] = df.groupby('book_theater_id')['audience_count'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).max().shift(1)\n",
    "    )\n",
    "\n",
    "# Fill NaN lag features with median\n",
    "lag_cols = [col for col in df.columns if 'lag_' in col or 'roll_' in col]\n",
    "for col in lag_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "# Average audience per theater\n",
    "theater_avg = df.groupby('book_theater_id')['audience_count'].mean().reset_index()\n",
    "theater_avg.columns = ['book_theater_id', 'theater_avg_audience']\n",
    "df = df.merge(theater_avg, on='book_theater_id', how='left')\n",
    "\n",
    "# Theater std\n",
    "theater_std = df.groupby('book_theater_id')['audience_count'].std().reset_index()\n",
    "theater_std.columns = ['book_theater_id', 'theater_std_audience']\n",
    "df = df.merge(theater_std, on='book_theater_id', how='left')\n",
    "df['theater_std_audience'] = df['theater_std_audience'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fcdee",
   "metadata": {
    "papermill": {
     "duration": 0.005542,
     "end_time": "2025-11-30T18:19:58.776548",
     "exception": false,
     "start_time": "2025-11-30T18:19:58.771006",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Encode Categorical Vairables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba3fa82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:58.789142Z",
     "iopub.status.busy": "2025-11-30T18:19:58.788776Z",
     "iopub.status.idle": "2025-11-30T18:19:59.017006Z",
     "shell.execute_reply": "2025-11-30T18:19:59.015802Z"
    },
    "papermill": {
     "duration": 0.236924,
     "end_time": "2025-11-30T18:19:59.018854",
     "exception": false,
     "start_time": "2025-11-30T18:19:58.781930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Label encode categorical columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = ['book_theater_id', 'day_of_week', 'theater_type', 'theater_area']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "        df[col + '_encoded'] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a4489",
   "metadata": {
    "papermill": {
     "duration": 0.005225,
     "end_time": "2025-11-30T18:19:59.029749",
     "exception": false,
     "start_time": "2025-11-30T18:19:59.024524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "114154bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:59.042310Z",
     "iopub.status.busy": "2025-11-30T18:19:59.041515Z",
     "iopub.status.idle": "2025-11-30T18:19:59.102936Z",
     "shell.execute_reply": "2025-11-30T18:19:59.101671Z"
    },
    "papermill": {
     "duration": 0.06978,
     "end_time": "2025-11-30T18:19:59.104799",
     "exception": false,
     "start_time": "2025-11-30T18:19:59.035019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: 46\n",
      "Training samples: 214046\n"
     ]
    }
   ],
   "source": [
    "# Select features for modeling\n",
    "feature_cols = [\n",
    "    'book_theater_id_encoded', 'day_of_week_encoded', 'theater_type_encoded', \n",
    "    'theater_area_encoded', 'year', 'month', 'day', 'day_of_year', 'week_of_year',\n",
    "    'is_weekend', 'is_friday', 'quarter',\n",
    "    'is_month_end', 'is_month_start', 'season', 'days_to_weekend',\n",
    "    'weekend_x_month', 'weekend_x_quarter',\n",
    "    'book_tickets_sum', 'book_tickets_mean', 'book_booking_count', 'book_tickets_max',\n",
    "    'cine_tickets_sum', 'cine_tickets_mean', 'cine_booking_count', 'cine_tickets_max',\n",
    "    'theater_avg_audience', 'theater_std_audience'\n",
    "]\n",
    "\n",
    "# Add lag features\n",
    "feature_cols.extend(lag_cols)\n",
    "\n",
    "# Remove any features not in df\n",
    "feature_cols = [col for col in feature_cols if col in df.columns]\n",
    "\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df['audience_count']\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Training samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36abab02",
   "metadata": {
    "papermill": {
     "duration": 0.005364,
     "end_time": "2025-11-30T18:19:59.115909",
     "exception": false,
     "start_time": "2025-11-30T18:19:59.110545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3f724e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:19:59.128293Z",
     "iopub.status.busy": "2025-11-30T18:19:59.127973Z",
     "iopub.status.idle": "2025-11-30T18:38:53.465729Z",
     "shell.execute_reply": "2025-11-30T18:38:53.464057Z"
    },
    "papermill": {
     "duration": 1134.352195,
     "end_time": "2025-11-30T18:38:53.473363",
     "exception": false,
     "start_time": "2025-11-30T18:19:59.121168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 174535, Validation size: 39511\n",
      "\n",
      "============================================================\n",
      "Training Random Forest...\n",
      "============================================================\n",
      "Training Time: 79.90s\n",
      "Train RMSE: 13.31 | Val RMSE: 21.05\n",
      "Train MAE: 8.39 | Val MAE: 14.84\n",
      "Train RÂ²: 0.8396 | Val RÂ²: 0.5355\n",
      "\n",
      "============================================================\n",
      "Training Gradient Boosting...\n",
      "============================================================\n",
      "Training Time: 1002.75s\n",
      "Train RMSE: 15.27 | Val RMSE: 21.87\n",
      "Train MAE: 11.21 | Val MAE: 15.09\n",
      "Train RÂ²: 0.7891 | Val RÂ²: 0.4988\n",
      "\n",
      "============================================================\n",
      "Training Extra Trees...\n",
      "============================================================\n",
      "Training Time: 33.86s\n",
      "Train RMSE: 15.17 | Val RMSE: 21.15\n",
      "Train MAE: 10.18 | Val MAE: 14.90\n",
      "Train RÂ²: 0.7919 | Val RÂ²: 0.5311\n",
      "\n",
      "================================================================================\n",
      "ðŸ“Š MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "            Model  Train RMSE  Val RMSE  Train MAE   Val MAE  Train RÂ²   Val RÂ²  Training Time (s)\n",
      "    Random Forest   13.314207 21.052830   8.387804 14.843346  0.839630 0.535497          79.896403\n",
      "Gradient Boosting   15.266554 21.867660  11.214571 15.092368  0.789150 0.498845        1002.752709\n",
      "      Extra Trees   15.165488 21.153316  10.177130 14.900582  0.791932 0.531052          33.859308\n",
      "\n",
      "ðŸ† BEST MODEL: Random Forest (Lowest Validation RMSE)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "\n",
    "# Split data (time-based split)\n",
    "split_date = pd.to_datetime('2024-01-01')\n",
    "train_mask = df['show_date'] < split_date\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val, y_val = X[~train_mask], y[~train_mask]\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=25,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Extra Trees': ExtraTreesRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=25,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Store trained model\n",
    "    trained_models[model_name] = model\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    \n",
    "    # Ensure non-negative predictions\n",
    "    y_pred_train = np.maximum(y_pred_train, 0)\n",
    "    y_pred_val = np.maximum(y_pred_val, 0)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train)\n",
    "    val_mae = mean_absolute_error(y_val, y_pred_val)\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    val_r2 = r2_score(y_val, y_pred_val)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Val RMSE': val_rmse,\n",
    "        'Train MAE': train_mae,\n",
    "        'Val MAE': val_mae,\n",
    "        'Train RÂ²': train_r2,\n",
    "        'Val RÂ²': val_r2,\n",
    "        'Training Time (s)': training_time\n",
    "    })\n",
    "    \n",
    "    print(f\"Training Time: {training_time:.2f}s\")\n",
    "    print(f\"Train RMSE: {train_rmse:.2f} | Val RMSE: {val_rmse:.2f}\")\n",
    "    print(f\"Train MAE: {train_mae:.2f} | Val MAE: {val_mae:.2f}\")\n",
    "    print(f\"Train RÂ²: {train_r2:.4f} | Val RÂ²: {val_r2:.4f}\")\n",
    "\n",
    "# Model comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_name = results_df.loc[results_df['Val RMSE'].idxmin(), 'Model']\n",
    "print(f\"\\nðŸ† BEST MODEL: {best_model_name} (Lowest Validation RMSE)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb48d0",
   "metadata": {
    "papermill": {
     "duration": 0.005739,
     "end_time": "2025-11-30T18:38:53.485068",
     "exception": false,
     "start_time": "2025-11-30T18:38:53.479329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffe9058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:38:53.499944Z",
     "iopub.status.busy": "2025-11-30T18:38:53.498612Z",
     "iopub.status.idle": "2025-11-30T18:38:53.506019Z",
     "shell.execute_reply": "2025-11-30T18:38:53.504743Z"
    },
    "papermill": {
     "duration": 0.017138,
     "end_time": "2025-11-30T18:38:53.507804",
     "exception": false,
     "start_time": "2025-11-30T18:38:53.490666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble weights: {'Random Forest': 0.5, 'Gradient Boosting': 0.3, 'Extra Trees': 0.2}\n"
     ]
    }
   ],
   "source": [
    "ensemble_weights = {\n",
    "    'Random Forest': 0.5,\n",
    "    'Gradient Boosting': 0.3,\n",
    "    'Extra Trees': 0.2\n",
    "}\n",
    "\n",
    "print(f\"Ensemble weights: {ensemble_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d59eb9",
   "metadata": {
    "papermill": {
     "duration": 0.005779,
     "end_time": "2025-11-30T18:38:53.519604",
     "exception": false,
     "start_time": "2025-11-30T18:38:53.513825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preparing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91890a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:38:53.532463Z",
     "iopub.status.busy": "2025-11-30T18:38:53.532093Z",
     "iopub.status.idle": "2025-11-30T18:39:21.756988Z",
     "shell.execute_reply": "2025-11-30T18:39:21.755468Z"
    },
    "papermill": {
     "duration": 28.23375,
     "end_time": "2025-11-30T18:39:21.758993",
     "exception": false,
     "start_time": "2025-11-30T18:38:53.525243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features for test data...\n",
      "Test samples: 38062\n"
     ]
    }
   ],
   "source": [
    "# Extract theater_id and date from submission ID\n",
    "sample_submission['book_theater_id'] = sample_submission['ID'].str.split('_').str[:2].str.join('_')\n",
    "sample_submission['show_date'] = pd.to_datetime(sample_submission['ID'].str.split('_').str[2])\n",
    "\n",
    "test_df = sample_submission[['book_theater_id', 'show_date']].copy()\n",
    "\n",
    "# Merge date info\n",
    "test_df = test_df.merge(date_info, on='show_date', how='left')\n",
    "\n",
    "# For dates not in date_info, infer day_of_week\n",
    "if test_df['day_of_week'].isna().any():\n",
    "    test_df['day_of_week'] = test_df['day_of_week'].fillna(\n",
    "        test_df['show_date'].dt.day_name()\n",
    "    )\n",
    "\n",
    "# Merge theater info\n",
    "test_df = test_df.merge(book_theaters_clean[['book_theater_id', 'theater_type', 'theater_area']], \n",
    "                       on='book_theater_id', how='left')\n",
    "\n",
    "# Merge booking features\n",
    "test_df = test_df.merge(book_agg, on=['book_theater_id', 'show_date'], how='left')\n",
    "test_df = test_df.merge(cine_agg, on=['book_theater_id', 'show_date'], how='left')\n",
    "\n",
    "# Fill missing booking features\n",
    "test_df[booking_cols] = test_df[booking_cols].fillna(0)\n",
    "\n",
    "# Time features\n",
    "test_df['year'] = test_df['show_date'].dt.year\n",
    "test_df['month'] = test_df['show_date'].dt.month\n",
    "test_df['day'] = test_df['show_date'].dt.day\n",
    "test_df['day_of_year'] = test_df['show_date'].dt.dayofyear\n",
    "test_df['week_of_year'] = test_df['show_date'].dt.isocalendar().week\n",
    "test_df['is_weekend'] = test_df['day_of_week'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "test_df['is_friday'] = (test_df['day_of_week'] == 'Friday').astype(int)\n",
    "test_df['quarter'] = test_df['show_date'].dt.quarter\n",
    "\n",
    "# Advanced time features (SAME AS TRAINING)\n",
    "test_df['is_month_end'] = (test_df['show_date'].dt.day > 25).astype(int)\n",
    "test_df['is_month_start'] = (test_df['show_date'].dt.day <= 5).astype(int)\n",
    "test_df['season'] = (test_df['month'] % 12 + 3) // 3\n",
    "test_df['days_to_weekend'] = test_df['day_of_week'].map({\n",
    "    'Monday': 5, 'Tuesday': 4, 'Wednesday': 3, 'Thursday': 2,\n",
    "    'Friday': 1, 'Saturday': 0, 'Sunday': 0\n",
    "})\n",
    "test_df['days_to_weekend'] = test_df['days_to_weekend'].fillna(0)\n",
    "test_df['weekend_x_month'] = test_df['is_weekend'] * test_df['month']\n",
    "test_df['weekend_x_quarter'] = test_df['is_weekend'] * test_df['quarter']\n",
    "\n",
    "# Theater average\n",
    "test_df = test_df.merge(theater_avg, on='book_theater_id', how='left')\n",
    "test_df['theater_avg_audience'] = test_df['theater_avg_audience'].fillna(\n",
    "    df['audience_count'].median()\n",
    ")\n",
    "\n",
    "# Theater std\n",
    "test_df = test_df.merge(theater_std, on='book_theater_id', how='left')\n",
    "test_df['theater_std_audience'] = test_df['theater_std_audience'].fillna(0)\n",
    "\n",
    "# CREATE LAG FEATURES FOR TEST\n",
    "print(\"Creating lag features for test data...\")\n",
    "\n",
    "# Combine train and test to properly compute lags\n",
    "combined_df = pd.concat([\n",
    "    df[['book_theater_id', 'show_date', 'audience_count']],\n",
    "    test_df[['book_theater_id', 'show_date']].assign(audience_count=np.nan)\n",
    "], ignore_index=True).sort_values(['book_theater_id', 'show_date'])\n",
    "\n",
    "# Create lag features on combined data (match training lags)\n",
    "for lag in [1, 3, 7, 14, 21, 28]:\n",
    "    combined_df[f'audience_lag_{lag}'] = combined_df.groupby('book_theater_id')['audience_count'].shift(lag)\n",
    "\n",
    "# Rolling statistics\n",
    "for window in [7, 14, 21, 28]:\n",
    "    combined_df[f'audience_roll_mean_{window}'] = combined_df.groupby('book_theater_id')['audience_count'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).mean().shift(1)\n",
    "    )\n",
    "    combined_df[f'audience_roll_std_{window}'] = combined_df.groupby('book_theater_id')['audience_count'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).std().shift(1)\n",
    "    )\n",
    "    combined_df[f'audience_roll_max_{window}'] = combined_df.groupby('book_theater_id')['audience_count'].transform(\n",
    "        lambda x: x.rolling(window=window, min_periods=1).max().shift(1)\n",
    "    )\n",
    "\n",
    "# Get only the lag columns for test data\n",
    "test_lag_data = combined_df[combined_df['audience_count'].isna()][\n",
    "    ['book_theater_id', 'show_date'] + lag_cols\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Merge lag features into test_df\n",
    "test_df = test_df.merge(\n",
    "    test_lag_data,\n",
    "    on=['book_theater_id', 'show_date'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill remaining NaNs with training medians\n",
    "for col in lag_cols:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna(df[col].median())\n",
    "\n",
    "# Encode categorical features\n",
    "for col in cat_cols:\n",
    "    if col in test_df.columns:\n",
    "        test_df[col] = test_df[col].fillna('Unknown')\n",
    "        test_df[col + '_encoded'] = test_df[col].astype(str).map(\n",
    "            lambda x: label_encoders[col].transform([x])[0] \n",
    "            if x in label_encoders[col].classes_ else -1\n",
    "        )\n",
    "        test_df[col + '_encoded'] = test_df[col + '_encoded'].fillna(-1)\n",
    "\n",
    "# Select features\n",
    "X_test = test_df[feature_cols].fillna(0)\n",
    "\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e264f1a",
   "metadata": {
    "papermill": {
     "duration": 0.006369,
     "end_time": "2025-11-30T18:39:21.771399",
     "exception": false,
     "start_time": "2025-11-30T18:39:21.765030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "098229d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:39:21.786075Z",
     "iopub.status.busy": "2025-11-30T18:39:21.785688Z",
     "iopub.status.idle": "2025-11-30T18:39:24.319161Z",
     "shell.execute_reply": "2025-11-30T18:39:24.317991Z"
    },
    "papermill": {
     "duration": 2.543554,
     "end_time": "2025-11-30T18:39:24.320908",
     "exception": false,
     "start_time": "2025-11-30T18:39:21.777354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest predictions - Mean: 39.77, Range: [4, 142]\n",
      "Gradient Boosting predictions - Mean: 41.47, Range: [2, 225]\n",
      "Extra Trees predictions - Mean: 39.45, Range: [4, 134]\n",
      "\n",
      "Final ensemble predictions:\n",
      "  Mean: 40.22\n",
      "  Median: 37.00\n",
      "  Range: [4, 159]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from all models\n",
    "all_predictions = []\n",
    "for model_name, model in trained_models.items():\n",
    "    pred = model.predict(X_test)\n",
    "    pred = np.maximum(pred, 0)\n",
    "    all_predictions.append(pred * ensemble_weights[model_name])\n",
    "    print(f\"{model_name} predictions - Mean: {pred.mean():.2f}, Range: [{pred.min():.0f}, {pred.max():.0f}]\")\n",
    "\n",
    "# Sum weighted predictions\n",
    "predictions = np.sum(all_predictions, axis=0)\n",
    "predictions = np.maximum(predictions, 0)\n",
    "predictions = np.round(predictions).astype(int)\n",
    "\n",
    "print(f\"\\nFinal ensemble predictions:\")\n",
    "print(f\"  Mean: {predictions.mean():.2f}\")\n",
    "print(f\"  Median: {np.median(predictions):.2f}\")\n",
    "print(f\"  Range: [{predictions.min()}, {predictions.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d4aca",
   "metadata": {
    "papermill": {
     "duration": 0.006262,
     "end_time": "2025-11-30T18:39:24.333641",
     "exception": false,
     "start_time": "2025-11-30T18:39:24.327379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22010031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T18:39:24.347240Z",
     "iopub.status.busy": "2025-11-30T18:39:24.346888Z",
     "iopub.status.idle": "2025-11-30T18:39:24.398903Z",
     "shell.execute_reply": "2025-11-30T18:39:24.397887Z"
    },
    "papermill": {
     "duration": 0.060952,
     "end_time": "2025-11-30T18:39:24.400531",
     "exception": false,
     "start_time": "2025-11-30T18:39:24.339579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Submission file saved as 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'ID': sample_submission['ID'],\n",
    "    'audience_count': predictions\n",
    "})\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nâœ… Submission file saved as 'submission.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13718043,
     "sourceId": 114451,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1184.457643,
   "end_time": "2025-11-30T18:39:25.330379",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-30T18:19:40.872736",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
